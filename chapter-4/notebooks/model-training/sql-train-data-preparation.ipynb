{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data.data_builder import load_data\n",
    "\n",
    "data = load_data(\"spider\", \"benchmarks\")\n",
    "\n",
    "train_metadata = data.get_train_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Results for Embedding Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embedding SFT Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from utils.linking.application import mask_question_with_schema_linking\n",
    "from utils.utils import mask_query\n",
    "from utils.utils import jaccard_similarity\n",
    "from third_party.TSED import tsed_similarity\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Obtain the relevant the data, for easy referencing in the main body loop\n",
    "temp = []\n",
    "\n",
    "for instance in tqdm(train_metadata):\n",
    "    \n",
    "    question = instance[\"question\"]\n",
    "    sql = instance[\"query\"]\n",
    "    masked_question = mask_question_with_schema_linking([instance],\"<mask>\",\"<unk>\")\n",
    "    masked_sql = mask_query(sql)\n",
    "    \n",
    "    temp.append({\"question\":question, \"masked_question\":masked_question, \"sql\":sql, \"masked_sql\":masked_sql})\n",
    "\n",
    "num_elements = len(temp)\n",
    "num_pairs = 1000000\n",
    "\n",
    "# Determine what sample of 100000 pairs of Spider questions to use in train set\n",
    "sampled_pairs = set()\n",
    "while len(sampled_pairs) < num_pairs:\n",
    "    i, j = random.randint(0, num_elements - 1), random.randint(0, num_elements - 1)\n",
    "    if i != j and (i, j) not in pairs:\n",
    "        sampled_pairs.add((i, j))\n",
    "\n",
    "\n",
    "# Create the dataset of 100000 masked (sql1, sql2, similarity_score) tuples\n",
    "dataset = []\n",
    "\n",
    "for indices in tqdm(sampled_pairs):\n",
    "    i = indices[0]\n",
    "    j = indices[1]\n",
    "    data_dict = {\n",
    "        \"sentence1\": temp[i][\"masked_sql\"],\n",
    "        \"sentence2\": temp[j][\"masked_sql\"],\n",
    "        \"score\": (tsed_similarity(\"sql\", temp[i][\"masked_sql\"], temp[j][\"masked_sql\"], 1, 0.8, 1) + jaccard_similarity(temp[i][\"masked_sql\"], temp[j][\"masked_sql\"])) / 2\n",
    "    }\n",
    "    dataset.append(data_dict)\n",
    "\n",
    "OUT_FILE = os.path.join(\"data\", \"spider\", \"train-sets\", \"sql-embedding-train-set.json\")\n",
    "with open(OUT_FILE, 'w') as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
